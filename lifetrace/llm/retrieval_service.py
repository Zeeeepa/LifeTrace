from datetime import datetime, timedelta
from typing import Any

from sqlalchemy import func, or_

from lifetrace.storage import get_session
from lifetrace.storage.models import Event, EventTaskRelation, OCRResult, Screenshot, Task
from lifetrace.util.logging_config import get_logger
from lifetrace.util.query_parser import QueryConditions, QueryParser

logger = get_logger()

# å¸¸é‡å®šä¹‰
MAX_LOG_PREVIEW_RECORDS = 3  # æ—¥å¿—é¢„è§ˆæœ€å¤§è®°å½•æ•°
MAX_APP_DISTRIBUTION_DISPLAY = 5  # åº”ç”¨åˆ†å¸ƒæ˜¾ç¤ºæœ€å¤§æ•°é‡
TIME_RECENCY_DAY_THRESHOLD = 1  # æ—¶é—´æ–°è¿‘æ€§é˜ˆå€¼ï¼ˆå¤©ï¼‰
TIME_RECENCY_WEEK_THRESHOLD = 7  # æ—¶é—´æ–°è¿‘æ€§é˜ˆå€¼ï¼ˆå‘¨ï¼‰


class RetrievalService:
    """æ£€ç´¢æœåŠ¡ï¼Œç”¨äºŽä»Žæ•°æ®åº“ä¸­æ£€ç´¢ç›¸å…³çš„æˆªå›¾å’ŒOCRæ•°æ®"""

    def __init__(self):
        """
        åˆå§‹åŒ–æ£€ç´¢æœåŠ¡
        """
        self.query_parser = QueryParser()
        logger.info("æ£€ç´¢æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    def _build_base_query(self, session: Any, conditions: QueryConditions) -> Any:
        """æž„å»ºåŸºç¡€æŸ¥è¯¢"""
        query = session.query(Screenshot).join(OCRResult, Screenshot.id == OCRResult.screenshot_id)

        # æ·»åŠ é¡¹ç›®è¿‡æ»¤
        if conditions.project_id:
            query = (
                query.join(Event, Screenshot.event_id == Event.id)
                .join(EventTaskRelation, Event.id == EventTaskRelation.event_id)
                .join(Task, EventTaskRelation.task_id == Task.id)
                .filter(Task.project_id == conditions.project_id)
            )

        # æ·»åŠ æ—¶é—´èŒƒå›´è¿‡æ»¤
        if conditions.start_date:
            query = query.filter(Screenshot.created_at >= conditions.start_date)
        if conditions.end_date:
            query = query.filter(Screenshot.created_at <= conditions.end_date)

        # æ·»åŠ åº”ç”¨åç§°è¿‡æ»¤
        if conditions.app_names:
            app_filters = [Screenshot.app_name.ilike(f"%{app}%") for app in conditions.app_names]
            query = query.filter(or_(*app_filters))

        # æ·»åŠ å…³é”®è¯è¿‡æ»¤
        if conditions.keywords:
            keyword_filters = [
                OCRResult.text_content.ilike(f"%{keyword}%") for keyword in conditions.keywords
            ]
            query = query.filter(or_(*keyword_filters))

        return query.order_by(Screenshot.created_at.desc())

    def _convert_screenshot_to_dict(
        self, session: Any, screenshot: Screenshot, conditions: QueryConditions
    ) -> dict[str, Any]:
        """å°†æˆªå›¾è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        ocr_results = (
            session.query(OCRResult).filter(OCRResult.screenshot_id == screenshot.id).all()
        )

        ocr_text = " ".join([ocr.text_content for ocr in ocr_results if ocr.text_content])

        return {
            "screenshot_id": screenshot.id,
            "timestamp": screenshot.created_at.isoformat() if screenshot.created_at else None,
            "app_name": screenshot.app_name,
            "window_title": screenshot.window_title,
            "file_path": screenshot.file_path,
            "ocr_text": ocr_text,
            "ocr_count": len(ocr_results),
            "relevance_score": self._calculate_relevance(screenshot, ocr_text, conditions),
        }

    def _log_query_results(self, data_list: list[dict[str, Any]]) -> None:
        """è®°å½•æŸ¥è¯¢ç»“æžœæ—¥å¿—"""
        logger.info("=" * 60)
        logger.info(f"ðŸ“Š æŸ¥è¯¢ç»“æžœ: æ‰¾åˆ° {len(data_list)} æ¡è®°å½•")
        logger.info("=" * 60)

        if not data_list:
            return

        logger.info("ðŸ“ OCRå†…å®¹è¯¦æƒ… (å‰3æ¡):")
        for i, item in enumerate(data_list[:MAX_LOG_PREVIEW_RECORDS]):
            ocr_text = item.get("ocr_text", "")
            logger.info(f"  [{i + 1}] æˆªå›¾ID: {item['screenshot_id']}")
            logger.info(f"      åº”ç”¨: {item['app_name']}")
            logger.info(f"      æ—¶é—´: {item['timestamp']}")
            logger.info(f"      OCRæ–‡æœ¬é•¿åº¦: {len(ocr_text)} å­—ç¬¦")
            logger.info(f"      OCRæ–‡æœ¬é¢„è§ˆ: {ocr_text[:100] if ocr_text else 'âŒ æ— OCRå†…å®¹'}")
            if not ocr_text:
                logger.warning("      âš ï¸  è­¦å‘Š: è¿™æ¡è®°å½•æ²¡æœ‰OCRæ–‡æœ¬ï¼")

        # ç»Ÿè®¡æœ‰æ— OCRå†…å®¹çš„è®°å½•
        has_ocr = sum(1 for item in data_list if item.get("ocr_text"))
        no_ocr = len(data_list) - has_ocr
        logger.info("ðŸ“ˆ OCRç»Ÿè®¡:")
        logger.info(f"   âœ… æœ‰OCRå†…å®¹: {has_ocr} æ¡")
        logger.info(f"   âŒ æ— OCRå†…å®¹: {no_ocr} æ¡")

        logger.info("=" * 60)
        logger.info("=== æŸ¥è¯¢å®Œæˆ ===")
        logger.info("=" * 60)

    def search_by_conditions(
        self, conditions: QueryConditions, limit: int = 50
    ) -> list[dict[str, Any]]:
        """
        æ ¹æ®æŸ¥è¯¢æ¡ä»¶æ£€ç´¢æ•°æ®

        Args:
            conditions: æŸ¥è¯¢æ¡ä»¶
            limit: è¿”å›žç»“æžœçš„æœ€å¤§æ•°é‡

        Returns:
            æ£€ç´¢åˆ°çš„æ•°æ®åˆ—è¡¨
        """
        try:
            logger.info(f"æ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢ - æ¡ä»¶: {conditions}, é™åˆ¶: {limit}")

            with get_session() as session:
                query = self._build_base_query(session, conditions)

                # é™åˆ¶ç»“æžœæ•°é‡ - ä¼˜å…ˆä½¿ç”¨QueryConditionsä¸­çš„limit
                effective_limit = conditions.limit if conditions.limit else limit
                results = query.limit(effective_limit).all()

                # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                data_list = [
                    self._convert_screenshot_to_dict(session, screenshot, conditions)
                    for screenshot in results
                ]

                # æŒ‰æ—¶é—´æŽ’åº
                data_list.sort(key=lambda x: x["timestamp"], reverse=True)

                # è®°å½•æŸ¥è¯¢ç»“æžœ
                self._log_query_results(data_list)

                logger.info(f"æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(data_list)} æ¡è®°å½•")
                return data_list

        except Exception as e:
            logger.error(f"æ•°æ®æ£€ç´¢å¤±è´¥: {e}")
            return []

    def search_by_query(self, user_query: str, limit: int = 50) -> list[dict[str, Any]]:
        """
        æ ¹æ®ç”¨æˆ·æŸ¥è¯¢æ£€ç´¢æ•°æ®

        Args:
            user_query: ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢
            limit: è¿”å›žç»“æžœçš„æœ€å¤§æ•°é‡

        Returns:
            æ£€ç´¢åˆ°çš„æ•°æ®åˆ—è¡¨
        """
        # è§£æžæŸ¥è¯¢
        conditions = self.query_parser.parse_query(user_query)
        logger.info(f"æŸ¥è¯¢è§£æžç»“æžœ: {conditions}")

        # æ‰§è¡Œæ£€ç´¢
        return self.search_by_conditions(conditions, limit)

    def search_recent(
        self, hours: int = 24, app_name: str = None, limit: int = 20
    ) -> list[dict[str, Any]]:
        """
        æ£€ç´¢æœ€è¿‘çš„è®°å½•

        Args:
            hours: æœ€è¿‘å¤šå°‘å°æ—¶çš„è®°å½•
            app_name: å¯é€‰çš„åº”ç”¨åç§°è¿‡æ»¤
            limit: è¿”å›žç»“æžœçš„æœ€å¤§æ•°é‡

        Returns:
            æ£€ç´¢åˆ°çš„æ•°æ®åˆ—è¡¨
        """
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=hours)

        conditions = QueryConditions(
            start_date=start_time,
            end_date=end_time,
            app_names=[app_name] if app_name else None,
        )

        return self.search_by_conditions(conditions, limit)

    def search_by_app(self, app_name: str, days: int = 7, limit: int = 50) -> list[dict[str, Any]]:
        """
        æŒ‰åº”ç”¨åç§°æ£€ç´¢è®°å½•

        Args:
            app_name: åº”ç”¨åç§°
            days: æ£€ç´¢æœ€è¿‘å¤šå°‘å¤©çš„è®°å½•
            limit: è¿”å›žç»“æžœçš„æœ€å¤§æ•°é‡

        Returns:
            æ£€ç´¢åˆ°çš„æ•°æ®åˆ—è¡¨
        """
        end_time = datetime.now()
        start_time = end_time - timedelta(days=days)

        conditions = QueryConditions(
            start_date=start_time,
            end_date=end_time,
            app_names=[app_name] if app_name else None,
        )

        return self.search_by_conditions(conditions, limit)

    def search_by_keywords(
        self, keywords: list[str], days: int = 30, limit: int = 50
    ) -> list[dict[str, Any]]:
        """
        æŒ‰å…³é”®è¯æ£€ç´¢è®°å½•

        Args:
            keywords: å…³é”®è¯åˆ—è¡¨
            days: æ£€ç´¢æœ€è¿‘å¤šå°‘å¤©çš„è®°å½•
            limit: è¿”å›žç»“æžœçš„æœ€å¤§æ•°é‡

        Returns:
            æ£€ç´¢åˆ°çš„æ•°æ®åˆ—è¡¨
        """
        end_time = datetime.now()
        start_time = end_time - timedelta(days=days)

        conditions = QueryConditions(start_date=start_time, end_date=end_time, keywords=keywords)

        return self.search_by_conditions(conditions, limit)

    def _apply_stats_conditions(self, query: Any, conditions: QueryConditions | None) -> Any:
        """åº”ç”¨ç»Ÿè®¡æŸ¥è¯¢æ¡ä»¶"""
        if not conditions:
            return query

        if conditions.project_id:
            query = (
                query.join(Event, Screenshot.event_id == Event.id)
                .join(EventTaskRelation, Event.id == EventTaskRelation.event_id)
                .join(Task, EventTaskRelation.task_id == Task.id)
                .filter(Task.project_id == conditions.project_id)
            )
        if conditions.start_date:
            query = query.filter(Screenshot.created_at >= conditions.start_date)
        if conditions.end_date:
            query = query.filter(Screenshot.created_at <= conditions.end_date)
        if conditions.app_names:
            app_filters = [Screenshot.app_name.ilike(f"%{app}%") for app in conditions.app_names]
            query = query.filter(or_(*app_filters))

        return query

    def _build_stats_result(
        self,
        total_count: int,
        app_stats: list[tuple[str, int]],
        time_range: Any,
        conditions: QueryConditions | None,
    ) -> dict[str, Any]:
        """æž„å»ºç»Ÿè®¡ç»“æžœ"""
        return {
            "total_screenshots": total_count,
            "app_distribution": dict(app_stats),
            "time_range": {
                "earliest": time_range.earliest.isoformat() if time_range.earliest else None,
                "latest": time_range.latest.isoformat() if time_range.latest else None,
            },
            "query_conditions": {
                "start_date": conditions.start_date.isoformat()
                if conditions and conditions.start_date
                else None,
                "end_date": conditions.end_date.isoformat()
                if conditions and conditions.end_date
                else None,
                "app_names": conditions.app_names if conditions else None,
                "keywords": conditions.keywords if conditions else [],
            },
        }

    def get_statistics(self, conditions: QueryConditions | None = None) -> dict[str, Any]:
        """
        èŽ·å–ç»Ÿè®¡ä¿¡æ¯

        Args:
            conditions: å¯é€‰çš„æŸ¥è¯¢æ¡ä»¶

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        try:
            logger.info("=== æ•°æ®åº“æŸ¥è¯¢ - get_statistics ===")
            logger.info(f"ç»Ÿè®¡æŸ¥è¯¢æ¡ä»¶: {conditions}")

            with get_session() as session:
                # åŸºç¡€æŸ¥è¯¢å¹¶åº”ç”¨æ¡ä»¶
                query = self._apply_stats_conditions(session.query(Screenshot), conditions)
                total_count = query.count()

                # æŒ‰åº”ç”¨åˆ†ç»„ç»Ÿè®¡
                app_stats_query = session.query(
                    Screenshot.app_name, func.count(Screenshot.id).label("count")
                ).group_by(Screenshot.app_name)
                app_stats_query = self._apply_stats_conditions(app_stats_query, conditions)
                app_stats = app_stats_query.all()

                # æ—¶é—´èŒƒå›´
                time_range = query.with_entities(
                    func.min(Screenshot.created_at).label("earliest"),
                    func.max(Screenshot.created_at).label("latest"),
                ).first()

                stats = self._build_stats_result(total_count, app_stats, time_range, conditions)

                # è®°å½•ç»Ÿè®¡ç»“æžœ
                logger.info(f"ç»Ÿè®¡ç»“æžœ: æ€»æˆªå›¾æ•°={total_count}")
                app_dist = stats["app_distribution"]
                app_preview = dict(list(app_dist.items())[:MAX_APP_DISTRIBUTION_DISPLAY])
                logger.info(
                    f"  åº”ç”¨åˆ†å¸ƒ: {app_preview}{'...' if len(app_dist) > MAX_APP_DISTRIBUTION_DISPLAY else ''}"
                )
                logger.info("=== ç»Ÿè®¡æŸ¥è¯¢å®Œæˆ ===")

                return stats

        except Exception as e:
            logger.error(f"ç»Ÿè®¡ä¿¡æ¯èŽ·å–å¤±è´¥: {e}")
            return {
                "total_screenshots": 0,
                "app_distribution": {},
                "time_range": {"earliest": None, "latest": None},
                "query_conditions": {},
            }

    def _calculate_relevance(
        self, screenshot: Screenshot, ocr_text: str, conditions: QueryConditions
    ) -> float:
        """
        è®¡ç®—ç›¸å…³æ€§å¾—åˆ†

        Args:
            screenshot: æˆªå›¾å¯¹è±¡
            ocr_text: OCRæ–‡æœ¬
            conditions: æŸ¥è¯¢æ¡ä»¶

        Returns:
            ç›¸å…³æ€§å¾—åˆ† (0.0 - 1.0)
        """
        score = 0.0

        # åº”ç”¨åç§°åŒ¹é…åŠ åˆ†
        if conditions.app_names and screenshot.app_name:
            if any(app.lower() in screenshot.app_name.lower() for app in conditions.app_names):
                score += 0.3

        # å…³é”®è¯åŒ¹é…åŠ åˆ†
        if conditions.keywords and ocr_text:
            text_lower = ocr_text.lower()
            keyword_matches = 0
            for keyword in conditions.keywords:
                if keyword.lower() in text_lower:
                    keyword_matches += 1

            if keyword_matches > 0:
                score += 0.5 * (keyword_matches / len(conditions.keywords))

        # æ—¶é—´æ–°è¿‘æ€§åŠ åˆ†
        if screenshot.created_at:
            now = datetime.now()
            time_diff = now - screenshot.created_at
            if time_diff.days < TIME_RECENCY_DAY_THRESHOLD:
                score += 0.2
            elif time_diff.days < TIME_RECENCY_WEEK_THRESHOLD:
                score += 0.1

        return min(score, 1.0)
