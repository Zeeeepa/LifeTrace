"""
RAG é¡¹ç›®åŠ©æ‰‹æ¨¡å—
åŒ…å«é¡¹ç›®ç›¸å…³çš„å¯¹è¯å¤„ç†é€»è¾‘
"""

from dataclasses import dataclass
from typing import Any

from lifetrace.storage import chat_mgr, project_mgr, task_mgr
from lifetrace.util.logging_config import get_logger
from lifetrace.util.prompt_loader import get_prompt
from lifetrace.util.settings import settings

logger = get_logger()


@dataclass
class ProjectContext:
    """é¡¹ç›®ä¸Šä¸‹æ–‡ä¿¡æ¯"""

    project_info: dict | None
    tasks_info_str: str
    selected_tasks_info_str: str | None


@dataclass
class RAGServices:
    """RAG æœåŠ¡ä¾èµ–é›†åˆ"""

    llm_client: Any
    query_parser: Any
    retrieval_service: Any
    context_builder: Any


def get_task_status_emoji(status: str) -> str:
    """è·å–ä»»åŠ¡çŠ¶æ€å¯¹åº”çš„ emoji"""
    return {
        "pending": "â³",
        "in_progress": "ğŸ”„",
        "completed": "âœ…",
        "cancelled": "âŒ",
    }.get(status, "ğŸ“")


def format_task_line(task: dict, truncate_desc: bool = True) -> str:
    """æ ¼å¼åŒ–å•ä¸ªä»»åŠ¡è¡Œ"""
    MAX_TASK_DESCRIPTION_LENGTH = 50
    status = task.get("status", "pending")
    status_emoji = get_task_status_emoji(status)
    task_line = f"{status_emoji} [{status}] {task.get('name', 'æœªå‘½åä»»åŠ¡')}"

    if task.get("description"):
        description = task.get("description")
        if truncate_desc and len(description) > MAX_TASK_DESCRIPTION_LENGTH:
            description = description[:MAX_TASK_DESCRIPTION_LENGTH] + "..."
        task_line += f"\n   æè¿°: {description}"
    return task_line


def get_project_tasks_info(project_id: int, task_ids: list[int] | None) -> ProjectContext:
    """è·å–é¡¹ç›®å’Œä»»åŠ¡ä¿¡æ¯"""
    project_info = project_mgr.get_project(project_id)
    logger.info(f"[stream] è·å–åˆ°é¡¹ç›®ä¿¡æ¯: {project_info}")

    tasks_info_str = "æš‚æ— ä»»åŠ¡"
    selected_tasks_info_str = None

    # è·å–æ‰€æœ‰ä»»åŠ¡
    tasks = task_mgr.list_tasks(project_id, limit=100)
    if tasks:
        tasks_info_str = "\n".join(format_task_line(task, truncate_desc=True) for task in tasks)
        logger.info(f"[stream] è·å–åˆ° {len(tasks)} ä¸ªä»»åŠ¡")
    else:
        logger.info(f"[stream] é¡¹ç›® {project_id} æš‚æ— ä»»åŠ¡")

    # è·å–é€‰ä¸­ä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯
    if task_ids:
        selected_tasks = []
        for task_id in task_ids:
            task = task_mgr.get_task(task_id)
            if task:
                selected_tasks.append(format_task_line(task, truncate_desc=False))
        if selected_tasks:
            selected_tasks_info_str = "\n\n".join(selected_tasks)
            logger.info(f"[stream] è·å–åˆ° {len(selected_tasks)} ä¸ªé€‰ä¸­çš„ä»»åŠ¡")

    return ProjectContext(
        project_info=project_info,
        tasks_info_str=tasks_info_str,
        selected_tasks_info_str=selected_tasks_info_str,
    )


def append_history_messages(messages: list, session_id: str, history_limit: int) -> None:
    """æ·»åŠ å†å²å¯¹è¯æ¶ˆæ¯"""
    try:
        history_messages = chat_mgr.get_messages(session_id, limit=history_limit * 2)
        for msg in history_messages:
            if msg["role"] in ["user", "assistant"]:
                messages.append({"role": msg["role"], "content": msg["content"]})
        if history_messages:
            logger.info(f"[stream] æ·»åŠ äº† {len(history_messages)} æ¡å†å²æ¶ˆæ¯")
    except Exception as e:
        logger.warning(f"[stream] è·å–å†å²æ¶ˆæ¯å¤±è´¥: {e}")


def get_system_prompt_for_project(ctx: ProjectContext, with_data: bool = False) -> str:
    """è·å–é¡¹ç›®å¯¹è¯çš„ç³»ç»Ÿæç¤ºè¯

    Args:
        ctx: é¡¹ç›®ä¸Šä¸‹æ–‡
        with_data: æ˜¯å¦åŒ…å«æ•°æ®
    """
    project_name = ctx.project_info.get("name", "æœªå‘½åé¡¹ç›®")
    project_goal = ctx.project_info.get("goal", "æš‚æ— ç›®æ ‡æè¿°")

    if with_data:
        if ctx.selected_tasks_info_str:
            return get_prompt(
                "project_assistant",
                "system_prompt_with_data_and_selected_tasks",
                project_name=project_name,
                project_goal=project_goal,
                selected_tasks_info=ctx.selected_tasks_info_str,
                tasks_info=ctx.tasks_info_str,
            )
        return get_prompt(
            "project_assistant",
            "system_prompt_with_data",
            project_name=project_name,
            project_goal=project_goal,
            tasks_info=ctx.tasks_info_str,
        )

    if ctx.selected_tasks_info_str:
        return get_prompt(
            "project_assistant",
            "system_prompt_with_selected_tasks",
            project_name=project_name,
            project_goal=project_goal,
            selected_tasks_info=ctx.selected_tasks_info_str,
            tasks_info=ctx.tasks_info_str,
        )
    return get_prompt(
        "project_assistant",
        "system_prompt",
        project_name=project_name,
        project_goal=project_goal,
        tasks_info=ctx.tasks_info_str,
    )


def build_messages_without_db(
    user_query: str,
    intent_result: dict,
    ctx: ProjectContext,
) -> list[dict]:
    """æ„å»ºä¸éœ€è¦æ•°æ®åº“æŸ¥è¯¢çš„æ¶ˆæ¯

    Args:
        user_query: ç”¨æˆ·æŸ¥è¯¢
        intent_result: æ„å›¾è¯†åˆ«ç»“æœ
        ctx: é¡¹ç›®ä¸Šä¸‹æ–‡
    """
    intent_type = intent_result.get("intent_type", "general_chat")

    if ctx.project_info:
        system_prompt = get_system_prompt_for_project(ctx, with_data=False)
    elif intent_type == "system_help":
        system_prompt = get_prompt("rag", "system_help")
    else:
        system_prompt = get_prompt("rag", "general_chat")

    return [{"role": "system", "content": system_prompt}]


def build_messages_with_db(
    user_query: str,
    project_id: int | None,
    ctx: ProjectContext,
    services: RAGServices,
) -> list[dict]:
    """æ„å»ºéœ€è¦æ•°æ®åº“æŸ¥è¯¢çš„æ¶ˆæ¯

    Args:
        user_query: ç”¨æˆ·æŸ¥è¯¢
        project_id: é¡¹ç›® ID
        ctx: é¡¹ç›®ä¸Šä¸‹æ–‡
        services: RAG æœåŠ¡ä¾èµ–é›†åˆ
    """
    from lifetrace.util.query_parser import QueryConditions

    parsed_query = services.query_parser.parse_query(user_query)
    if project_id:
        parsed_query.project_id = project_id

    query_type = "statistics" if "ç»Ÿè®¡" in user_query else "search"
    retrieved_data = services.retrieval_service.search_by_conditions(parsed_query, 500)

    # æ„å»ºä¸Šä¸‹æ–‡
    if query_type == "statistics":
        stats = None
        if isinstance(parsed_query, QueryConditions):
            stats = services.retrieval_service.get_statistics(parsed_query)
        context_text = services.context_builder.build_statistics_context(
            user_query, retrieved_data, stats
        )
    else:
        context_text = services.context_builder.build_search_context(user_query, retrieved_data)
    logger.debug(f"æ„å»ºçš„ä¸Šä¸‹æ–‡å†…å®¹: {context_text}")

    # ç¡®å®šç³»ç»Ÿå†…å®¹
    if ctx.project_info:
        project_context = get_system_prompt_for_project(ctx, with_data=True)
        system_content = f"{project_context}\n\n{context_text}"
    else:
        system_content = context_text

    return [{"role": "system", "content": system_content}]


async def process_query_stream(
    user_query: str,
    project_id: int | None,
    task_ids: list[int] | None,
    session_id: str | None,
    services: RAGServices,
) -> dict[str, Any]:
    """ä¸ºæµå¼æ¥å£å¤„ç†æŸ¥è¯¢ï¼Œè¿”å›æ„å»ºå¥½çš„messageså’Œtemperature

    Args:
        user_query: ç”¨æˆ·æŸ¥è¯¢
        project_id: é¡¹ç›® ID
        task_ids: ä»»åŠ¡ ID åˆ—è¡¨
        session_id: ä¼šè¯ ID
        services: RAG æœåŠ¡ä¾èµ–é›†åˆ
    """
    try:
        logger.info(
            f"[stream] å¼€å§‹å¤„ç†æŸ¥è¯¢: {user_query}, project_id: {project_id}, "
            f"task_ids: {task_ids}, session_id: {session_id}"
        )
        intent_result = services.llm_client.classify_intent(user_query)
        needs_db = intent_result.get("needs_database", True)

        # è·å–å†å²å¯¹è¯é…ç½®
        enable_history = settings.chat.enable_history
        history_limit = settings.chat.history_limit

        # è·å–é¡¹ç›®å’Œä»»åŠ¡ä¿¡æ¯
        ctx = ProjectContext(
            project_info=None, tasks_info_str="æš‚æ— ä»»åŠ¡", selected_tasks_info_str=None
        )
        if project_id:
            ctx = get_project_tasks_info(project_id, task_ids)

        # æ„å»ºæ¶ˆæ¯
        if needs_db:
            messages = build_messages_with_db(user_query, project_id, ctx, services)
            temperature = 0.3
        else:
            messages = build_messages_without_db(user_query, intent_result, ctx)
            temperature = 0.7

        # æ·»åŠ å†å²å¯¹è¯
        if enable_history and session_id and history_limit > 0:
            append_history_messages(messages, session_id, history_limit)

        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": user_query})

        return {
            "success": True,
            "messages": messages,
            "temperature": temperature,
            "intent_result": intent_result,
        }

    except Exception as e:
        logger.error(f"[stream] å¤„ç†æŸ¥è¯¢å¤±è´¥: {e}")
        return {
            "success": False,
            "response": f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºç°é”™è¯¯: {str(e)}",
            "messages": [],
            "temperature": 0.7,
        }
