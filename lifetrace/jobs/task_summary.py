"""ä»»åŠ¡è¿›å±•æ‘˜è¦æœåŠ¡

æ­¤æœåŠ¡é€šè¿‡ APScheduler è°ƒåº¦å™¨è¿è¡Œï¼Œå®šæœŸæ£€æŸ¥å“ªäº›ä»»åŠ¡æœ‰è¶³å¤Ÿå¤šçš„æ–°å…³è”ä¸Šä¸‹æ–‡ï¼Œ
å¹¶ä½¿ç”¨ LLM è‡ªåŠ¨ç”Ÿæˆè¿›å±•æ‘˜è¦ï¼Œè¿½åŠ åˆ°ä»»åŠ¡æè¿°ä¸­ã€‚
"""

import threading
from datetime import datetime
from typing import Any

from lifetrace.llm.llm_client import LLMClient
from lifetrace.storage import (
    context_mgr,
    event_mgr,
    get_session,
    ocr_mgr,
    project_mgr,
    task_mgr,
)
from lifetrace.util.config import config
from lifetrace.util.logging_config import get_logger

logger = get_logger()

# å…¨å±€æœåŠ¡å®ä¾‹ï¼ˆç”¨äºè°ƒåº¦å™¨ä»»åŠ¡ï¼‰
_global_summary_instance = None


class TaskSummaryService:
    """ä»»åŠ¡è¿›å±•æ‘˜è¦æœåŠ¡"""

    def __init__(
        self,
        llm_client: LLMClient = None,
        min_new_contexts: int = 5,
        check_interval: int = 3600,  # é»˜è®¤1å°æ—¶
        enabled: bool = True,
    ):
        """
        åˆå§‹åŒ–ä»»åŠ¡æ‘˜è¦æœåŠ¡

        Args:
            llm_client: LLMå®¢æˆ·ç«¯ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨åˆ›å»º
            min_new_contexts: è§¦å‘æ‘˜è¦çš„æœ€å°æ–°ä¸Šä¸‹æ–‡æ•°é‡
            check_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤3600ç§’ï¼ˆ1å°æ—¶ï¼‰
            enabled: æ˜¯å¦å¯ç”¨æœåŠ¡
        """
        self.llm_client = llm_client or LLMClient()
        self.min_new_contexts = min_new_contexts
        self.check_interval = check_interval
        self.enabled = enabled

        self._thread = None
        self._stop_event = threading.Event()
        self._running = False

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_tasks_processed": 0,
            "total_summaries_generated": 0,
            "total_contexts_summarized": 0,
            "last_run_time": None,
            "last_error": None,
        }

        logger.info(
            f"ä»»åŠ¡æ‘˜è¦æœåŠ¡åˆå§‹åŒ–å®Œæˆ - "
            f"æœ€å°æ–°ä¸Šä¸‹æ–‡æ•°: {min_new_contexts}, "
            f"æ£€æŸ¥é—´éš”: {check_interval}ç§’, "
            f"å¯ç”¨çŠ¶æ€: {enabled}"
        )

    def start(self):
        """å¯åŠ¨åå°æœåŠ¡çº¿ç¨‹"""
        if not self.enabled:
            logger.info("ä»»åŠ¡æ‘˜è¦æœåŠ¡æœªå¯ç”¨ï¼Œè·³è¿‡å¯åŠ¨")
            return

        if self._running:
            logger.warning("ä»»åŠ¡æ‘˜è¦æœåŠ¡å·²åœ¨è¿è¡Œä¸­")
            return

        self._stop_event.clear()
        self._running = True
        self._thread = threading.Thread(target=self._run_loop, daemon=True)
        self._thread.start()
        logger.info("ä»»åŠ¡æ‘˜è¦æœåŠ¡å·²å¯åŠ¨")

    def stop(self):
        """åœæ­¢åå°æœåŠ¡çº¿ç¨‹"""
        if not self._running:
            return

        logger.error("æ­£åœ¨åœæ­¢ä»»åŠ¡æ‘˜è¦æœåŠ¡...")
        self._stop_event.set()
        if self._thread:
            self._thread.join(timeout=10)
        self._running = False
        logger.error("ä»»åŠ¡æ‘˜è¦æœåŠ¡å·²åœæ­¢")

    def is_running(self) -> bool:
        """æ£€æŸ¥æœåŠ¡æ˜¯å¦åœ¨è¿è¡Œ"""
        return self._running

    def get_stats(self) -> dict[str, Any]:
        """è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        return self.stats.copy()

    def _run_loop(self):
        """æœåŠ¡ä¸»å¾ªç¯"""
        logger.info("ä»»åŠ¡æ‘˜è¦æœåŠ¡ä¸»å¾ªç¯å·²å¯åŠ¨")

        while not self._stop_event.is_set():
            try:
                self._process_all_tasks()
                self.stats["last_run_time"] = datetime.now().isoformat()
            except Exception as e:
                error_msg = f"å¤„ç†ä»»åŠ¡æ‘˜è¦æ—¶å‘ç”Ÿé”™è¯¯: {e}"
                logger.error(error_msg)
                logger.exception(e)
                self.stats["last_error"] = error_msg

            # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
            self._stop_event.wait(timeout=self.check_interval)

        logger.info("ä»»åŠ¡æ‘˜è¦æœåŠ¡ä¸»å¾ªç¯å·²é€€å‡º")

    def _process_all_tasks(self):
        """
        å¤„ç†æ‰€æœ‰éœ€è¦ç”Ÿæˆæ‘˜è¦çš„ä»»åŠ¡

        a. æ£€æŸ¥å“ªäº›ä»»åŠ¡æœ‰è¶³å¤Ÿå¤šçš„ã€å°šæœªè¢«æ‘˜è¦çš„æ–°å…³è”ä¸Šä¸‹æ–‡
        """
        try:
            # è·å–æ‰€æœ‰é¡¹ç›®
            projects = project_mgr.list_projects(limit=1000, offset=0)

            if not projects:
                logger.debug("ç³»ç»Ÿä¸­æ²¡æœ‰é¡¹ç›®")
                return

            tasks_need_summary = []

            # éå†æ‰€æœ‰é¡¹ç›®çš„æ‰€æœ‰ä»»åŠ¡
            for project in projects:
                project_id = project["id"]
                tasks = task_mgr.list_tasks(project_id=project_id, limit=1000, offset=0)

                for task in tasks:
                    task_id = task["id"]

                    # è·å–è¯¥ä»»åŠ¡å…³è”çš„æ‰€æœ‰ä¸Šä¸‹æ–‡ï¼Œåªè·å–æœªè¢«ç”¨äºæ‘˜è¦çš„
                    new_contexts = context_mgr.list_contexts(
                        task_id=task_id, used_in_summary=False, limit=1000, offset=0
                    )

                    if not new_contexts:
                        continue

                    if len(new_contexts) >= self.min_new_contexts:
                        tasks_need_summary.append(
                            {"task": task, "project": project, "new_contexts": new_contexts}
                        )
                        logger.info(
                            f"ä»»åŠ¡ {task_id} ({task['name']}) æœ‰ "
                            f"{len(new_contexts)} ä¸ªæ–°ä¸Šä¸‹æ–‡ï¼Œå°†ç”Ÿæˆæ‘˜è¦"
                        )

            if not tasks_need_summary:
                logger.debug("æ²¡æœ‰ä»»åŠ¡éœ€è¦ç”Ÿæˆæ‘˜è¦")
                return

            logger.info(f"æ‰¾åˆ° {len(tasks_need_summary)} ä¸ªä»»åŠ¡éœ€è¦ç”Ÿæˆæ‘˜è¦")

            # ä¸ºæ¯ä¸ªä»»åŠ¡ç”Ÿæˆæ‘˜è¦
            for item in tasks_need_summary:
                try:
                    self._generate_summary_for_task(
                        task=item["task"],
                        project=item["project"],
                        new_contexts=item["new_contexts"],
                    )
                    self.stats["total_tasks_processed"] += 1
                except Exception as e:
                    logger.error(f"ä¸ºä»»åŠ¡ {item['task']['id']} ç”Ÿæˆæ‘˜è¦æ—¶å‡ºé”™: {e}")
                    logger.exception(e)

        except Exception as e:
            logger.error(f"å¤„ç†æ‰€æœ‰ä»»åŠ¡æ—¶å‡ºé”™: {e}")
            logger.exception(e)

    def _generate_summary_for_task(
        self, task: dict[str, Any], project: dict[str, Any], new_contexts: list[dict[str, Any]]
    ):
        """
        ä¸ºä»»åŠ¡ç”Ÿæˆè¿›å±•æ‘˜è¦

        b. æ„å»ºé¢å‘ LLM çš„æ‘˜è¦ Prompt
           ï¼ˆåŒ…å«ä»»åŠ¡åç§°å’Œæ‰€æœ‰æ–°çš„ä¸Šä¸‹æ–‡æ–‡æœ¬ï¼‰
        c. è°ƒç”¨ LLM APIï¼Œè·å–ç”Ÿæˆçš„"è¿›å±•æ‘˜è¦"
        d. å°†æ‘˜è¦æ–‡æœ¬è¿½åŠ åˆ° tasks è¡¨çš„ description å­—æ®µä¸­ï¼Œ
           å¹¶åšå¥½æ ¼å¼åŒ–

        Args:
            task: ä»»åŠ¡ä¿¡æ¯
            project: é¡¹ç›®ä¿¡æ¯
            new_contexts: æ–°çš„ä¸Šä¸‹æ–‡åˆ—è¡¨
        """
        task_id = task["id"]
        task_name = task["name"]
        task_description = task.get("description", "")

        logger.info(
            f"å¼€å§‹ä¸ºä»»åŠ¡ {task_id} ({task_name}) ç”Ÿæˆæ‘˜è¦ï¼ŒåŸºäº {len(new_contexts)} ä¸ªæ–°ä¸Šä¸‹æ–‡"
        )

        # æ”¶é›†æ‰€æœ‰æ–°ä¸Šä¸‹æ–‡çš„è¯¦ç»†ä¿¡æ¯
        context_details = []
        for context in new_contexts:
            # è·å–ä¸Šä¸‹æ–‡çš„æˆªå›¾å’ŒOCRæ–‡æœ¬
            screenshots = self._get_screenshots_for_context(context["id"])

            ocr_texts = []
            for screenshot in screenshots[:3]:  # æ¯ä¸ªä¸Šä¸‹æ–‡æœ€å¤šå–3ä¸ªæˆªå›¾
                ocr_results = ocr_mgr.get_ocr_results_by_screenshot(screenshot["id"])
                for ocr_result in ocr_results:
                    if ocr_result and ocr_result.get("text_content"):
                        ocr_texts.append(ocr_result["text_content"])

            context_info = {
                "id": context["id"],
                "app_name": context.get("app_name", "æœªçŸ¥"),
                "window_title": context.get("window_title", ""),
                "start_time": context.get("start_time", ""),
                "end_time": context.get("end_time", ""),
                "ai_title": context.get("ai_title", ""),
                "ai_summary": context.get("ai_summary", ""),
                "ocr_texts": ocr_texts,
            }
            context_details.append(context_info)

        # b. æ„å»ºé¢å‘ LLM çš„æ‘˜è¦ Prompt
        prompt = self._build_summary_prompt(
            task=task, project=project, context_details=context_details
        )

        # c. è°ƒç”¨ LLM APIï¼Œè·å–ç”Ÿæˆçš„"è¿›å±•æ‘˜è¦"
        summary = self._call_llm_for_summary(prompt)

        if not summary:
            logger.warning(f"ä»»åŠ¡ {task_id} çš„æ‘˜è¦ç”Ÿæˆå¤±è´¥")
            return

        # d. å°†æ‘˜è¦æ–‡æœ¬è¿½åŠ åˆ° tasks è¡¨çš„ description å­—æ®µä¸­
        success = self._append_summary_to_task(task_id, summary, task_description)

        if success:
            # æ ‡è®°è¿™äº›ä¸Šä¸‹æ–‡å·²è¢«æ‘˜è¦ï¼ˆåœ¨æ•°æ®åº“ä¸­æ ‡è®°ï¼‰
            event_ids = [ctx["id"] for ctx in new_contexts]
            context_mgr.mark_contexts_used_in_summary(task_id, event_ids)

            self.stats["total_summaries_generated"] += 1
            self.stats["total_contexts_summarized"] += len(new_contexts)

            logger.info(
                f"âœ… æˆåŠŸä¸ºä»»åŠ¡ {task_id} ({task_name}) ç”Ÿæˆå¹¶ä¿å­˜æ‘˜è¦ï¼Œ"
                f"æ‘˜è¦äº† {len(new_contexts)} ä¸ªä¸Šä¸‹æ–‡"
            )
        else:
            logger.error(f"âŒ ä¿å­˜ä»»åŠ¡ {task_id} çš„æ‘˜è¦å¤±è´¥")

    def _get_screenshots_for_context(self, context_id: int) -> list[dict[str, Any]]:
        """
        è·å–ä¸Šä¸‹æ–‡å…³è”çš„æˆªå›¾

        Args:
            context_id: ä¸Šä¸‹æ–‡IDï¼ˆå³äº‹ä»¶IDï¼‰

        Returns:
            æˆªå›¾åˆ—è¡¨
        """
        try:
            screenshots = event_mgr.get_event_screenshots(context_id)
            return screenshots
        except Exception as e:
            logger.error(f"è·å–ä¸Šä¸‹æ–‡ {context_id} çš„æˆªå›¾å¤±è´¥: {e}")
            logger.exception(e)
            return []

    def _build_summary_prompt(
        self, task: dict[str, Any], project: dict[str, Any], context_details: list[dict[str, Any]]
    ) -> dict[str, str]:
        """
        æ„å»ºç”¨äºLLMç”Ÿæˆæ‘˜è¦çš„æç¤º

        Args:
            task: ä»»åŠ¡ä¿¡æ¯
            project: é¡¹ç›®ä¿¡æ¯
            context_details: ä¸Šä¸‹æ–‡è¯¦ç»†ä¿¡æ¯åˆ—è¡¨

        Returns:
            åŒ…å«systemå’Œuseræ¶ˆæ¯çš„å­—å…¸
        """
        task_name = task["name"]
        task_description = task.get("description", "æ— ")
        project_name = project["name"]
        project_goal = project.get("goal", "æ— ")

        # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯å­—ç¬¦ä¸²
        contexts_info = []
        for i, ctx in enumerate(context_details, 1):
            ctx_str = f"ã€ä¸Šä¸‹æ–‡ {i}ã€‘\n"
            ctx_str += f"- åº”ç”¨: {ctx['app_name']}\n"
            if ctx.get("window_title"):
                ctx_str += f"- çª—å£æ ‡é¢˜: {ctx['window_title']}\n"
            ctx_str += f"- æ—¶é—´: {ctx.get('start_time', 'æœªçŸ¥')} è‡³ {ctx.get('end_time', 'æœªçŸ¥')}\n"

            if ctx.get("ai_title"):
                ctx_str += f"- AIæ ‡é¢˜: {ctx['ai_title']}\n"
            if ctx.get("ai_summary"):
                ctx_str += f"- AIæ‘˜è¦: {ctx['ai_summary']}\n"

            if ctx.get("ocr_texts"):
                # åˆå¹¶OCRæ–‡æœ¬ï¼Œé™åˆ¶é•¿åº¦
                combined_text = "\n".join(ctx["ocr_texts"])
                if len(combined_text) > 500:
                    combined_text = combined_text[:500] + "..."
                ctx_str += f"- å†…å®¹æ–‡æœ¬:\n{combined_text}\n"

            contexts_info.append(ctx_str)

        contexts_str = "\n".join(contexts_info)

        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œä¸“é—¨ç”¨äºåˆ†æç”¨æˆ·çš„å·¥ä½œä¸Šä¸‹æ–‡å¹¶ç”Ÿæˆä»»åŠ¡è¿›å±•æ‘˜è¦ã€‚

ä½ ä¼šæ”¶åˆ°ï¼š
1. é¡¹ç›®ä¿¡æ¯ï¼ˆåç§°ã€ç›®æ ‡ï¼‰
2. ä»»åŠ¡ä¿¡æ¯ï¼ˆåç§°ã€å½“å‰æè¿°ï¼‰
3. ä¸€ç³»åˆ—æ–°çš„ä¸Šä¸‹æ–‡è®°å½•ï¼ˆåº”ç”¨æ´»åŠ¨ã€æ—¶é—´ã€å†…å®¹ç­‰ï¼‰

è¯·åŸºäºè¿™äº›æ–°çš„ä¸Šä¸‹æ–‡è®°å½•ï¼Œç”Ÿæˆä¸€æ®µç®€æ´çš„è¿›å±•æ‘˜è¦ï¼Œæè¿°ç”¨æˆ·åœ¨è¿™ä¸ªä»»åŠ¡ä¸Šåšäº†ä»€ä¹ˆå·¥ä½œã€‚

è¦æ±‚ï¼š
1. æ‘˜è¦åº”è¯¥ç®€æ´æ˜äº†ï¼Œä¸è¶…è¿‡200å­—
2. é‡ç‚¹å…³æ³¨å®é™…å·¥ä½œå†…å®¹å’Œè¿›å±•
3. å¦‚æœèƒ½è¯†åˆ«å‡ºå…·ä½“çš„å·¥ä½œæˆæœæˆ–é‡Œç¨‹ç¢‘ï¼Œè¯·ç‰¹åˆ«è¯´æ˜
4. ä½¿ç”¨å‹å¥½ã€è‡ªç„¶çš„è¯­è¨€
5. ä¸è¦é‡å¤ä»»åŠ¡åç§°æˆ–é¡¹ç›®åç§°
6. ç›´æ¥è¾“å‡ºæ‘˜è¦æ–‡æœ¬ï¼Œä¸è¦æ·»åŠ ä»»ä½•å‰ç¼€æˆ–æ ‡é¢˜

åªè¿”å›æ‘˜è¦æ–‡æœ¬ï¼Œä¸è¦è¿”å›å…¶ä»–ä»»ä½•ä¿¡æ¯ã€‚"""

        user_prompt = f"""é¡¹ç›®ä¿¡æ¯ï¼š
- é¡¹ç›®åç§°: {project_name}
- é¡¹ç›®ç›®æ ‡: {project_goal}

ä»»åŠ¡ä¿¡æ¯ï¼š
- ä»»åŠ¡åç§°: {task_name}
- å½“å‰æè¿°: {task_description}

æ–°çš„å·¥ä½œä¸Šä¸‹æ–‡ï¼ˆå…± {len(context_details)} æ¡ï¼‰ï¼š
{contexts_str}

è¯·åŸºäºä»¥ä¸Šæ–°çš„ä¸Šä¸‹æ–‡è®°å½•ï¼Œç”Ÿæˆä¸€æ®µä»»åŠ¡è¿›å±•æ‘˜è¦ã€‚"""

        return {"system": system_prompt, "user": user_prompt}

    def _call_llm_for_summary(self, prompt: dict[str, str]) -> str | None:
        """
        è°ƒç”¨LLMç”Ÿæˆæ‘˜è¦

        Args:
            prompt: æç¤ºä¿¡æ¯

        Returns:
            ç”Ÿæˆçš„æ‘˜è¦æ–‡æœ¬
        """
        if not self.llm_client.is_available():
            logger.warning("LLMå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œæ— æ³•ç”Ÿæˆæ‘˜è¦")
            return None

        try:
            response = self.llm_client.client.chat.completions.create(
                model=self.llm_client.model,
                messages=[
                    {"role": "system", "content": prompt["system"]},
                    {"role": "user", "content": prompt["user"]},
                ],
                temperature=0.3,
                max_tokens=500,
            )

            # è®°å½•tokenä½¿ç”¨é‡
            if hasattr(response, "usage") and response.usage:
                from lifetrace.util.token_usage_logger import log_token_usage

                log_token_usage(
                    model=self.llm_client.model,
                    input_tokens=response.usage.prompt_tokens,
                    output_tokens=response.usage.completion_tokens,
                    endpoint="task_summary",
                    response_type="summary_generation",
                    feature_type="job_task_summary",
                )

            summary = response.choices[0].message.content.strip()

            logger.debug(f"LLMç”Ÿæˆçš„æ‘˜è¦: {summary}")

            return summary

        except Exception as e:
            logger.error(f"è°ƒç”¨LLMç”Ÿæˆæ‘˜è¦å¤±è´¥: {e}")
            logger.exception(e)
            return None

    def _append_summary_to_task(self, task_id: int, summary: str, current_description: str) -> bool:
        """
        å°†æ‘˜è¦è¿½åŠ åˆ°ä»»åŠ¡æè¿°ä¸­

        Args:
            task_id: ä»»åŠ¡ID
            summary: æ‘˜è¦æ–‡æœ¬
            current_description: å½“å‰æè¿°

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # æ ¼å¼åŒ–æ‘˜è¦ï¼Œæ·»åŠ æ—¶é—´æˆ³å’Œå‰ç¼€
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            formatted_summary = f"\n\n---\n**AI æ‘˜è¦** ({timestamp}):\n{summary}"

            # å°†æ‘˜è¦è¿½åŠ åˆ°ç°æœ‰æè¿°
            if current_description:
                new_description = current_description + formatted_summary
            else:
                new_description = formatted_summary.strip()

            # æ›´æ–°ä»»åŠ¡æè¿°
            success = task_mgr.update_task(task_id=task_id, description=new_description)

            if success:
                logger.info(f"æˆåŠŸå°†æ‘˜è¦è¿½åŠ åˆ°ä»»åŠ¡ {task_id} çš„æè¿°ä¸­")
            else:
                logger.error(f"æ›´æ–°ä»»åŠ¡ {task_id} çš„æè¿°å¤±è´¥")

            return success

        except Exception as e:
            logger.error(f"è¿½åŠ æ‘˜è¦åˆ°ä»»åŠ¡ {task_id} å¤±è´¥: {e}")
            logger.exception(e)
            return False

    def trigger_manual_summary(self, task_id: int) -> dict[str, Any]:
        """
        æ‰‹åŠ¨è§¦å‘ä»»åŠ¡æ‘˜è¦ç”Ÿæˆï¼ˆä¾›APIè°ƒç”¨ï¼‰

        Args:
            task_id: ä»»åŠ¡ID

        Returns:
            ç»“æœä¿¡æ¯
        """
        try:
            # è·å–ä»»åŠ¡ä¿¡æ¯
            task = task_mgr.get_task(task_id)
            if not task:
                return {"success": False, "message": f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨"}

            # è·å–é¡¹ç›®ä¿¡æ¯
            project = project_mgr.get_project(task["project_id"])
            if not project:
                return {"success": False, "message": f"é¡¹ç›® {task['project_id']} ä¸å­˜åœ¨"}

            # è·å–è¯¥ä»»åŠ¡å…³è”çš„æ‰€æœ‰ä¸Šä¸‹æ–‡ï¼Œåªè·å–æœªè¢«ç”¨äºæ‘˜è¦çš„
            new_contexts = context_mgr.list_contexts(
                task_id=task_id, used_in_summary=False, limit=1000, offset=0
            )

            if not new_contexts:
                return {"success": False, "message": f"ä»»åŠ¡ {task_id} æ²¡æœ‰æ–°çš„ä¸Šä¸‹æ–‡éœ€è¦æ‘˜è¦"}

            # ç”Ÿæˆæ‘˜è¦
            self._generate_summary_for_task(task=task, project=project, new_contexts=new_contexts)

            return {
                "success": True,
                "message": f"æˆåŠŸä¸ºä»»åŠ¡ {task_id} ç”Ÿæˆæ‘˜è¦",
                "contexts_summarized": len(new_contexts),
            }

        except Exception as e:
            logger.error(f"æ‰‹åŠ¨è§¦å‘ä»»åŠ¡ {task_id} æ‘˜è¦å¤±è´¥: {e}")
            logger.exception(e)
            return {"success": False, "message": f"ç”Ÿæˆæ‘˜è¦å¤±è´¥: {str(e)}"}

    def clear_summary_history(self, task_id: int | None = None):
        """
        æ¸…é™¤æ‘˜è¦å†å²è®°å½•ï¼ˆç”¨äºé‡æ–°ç”Ÿæˆæ‘˜è¦ï¼‰

        å°†æ•°æ®åº“ä¸­çš„ used_in_summary æ ‡è®°é‡ç½®ä¸º False

        Args:
            task_id: ä»»åŠ¡IDï¼Œå¦‚æœä¸ºNoneåˆ™æ¸…é™¤æ‰€æœ‰ä»»åŠ¡çš„å†å²
        """
        try:
            from sqlalchemy import update

            from lifetrace.storage.models import EventTaskRelation

            with get_session() as session:
                if task_id is None:
                    # é‡ç½®æ‰€æœ‰è®°å½•
                    stmt = update(EventTaskRelation).values(used_in_summary=False)
                    result = session.execute(stmt)
                    session.commit()
                    logger.info(f"å·²æ¸…é™¤æ‰€æœ‰ä»»åŠ¡çš„æ‘˜è¦å†å²è®°å½•ï¼ˆé‡ç½®äº† {result.rowcount} æ¡è®°å½•ï¼‰")
                else:
                    # åªé‡ç½®æŒ‡å®šä»»åŠ¡çš„è®°å½•
                    stmt = (
                        update(EventTaskRelation)
                        .where(EventTaskRelation.task_id == task_id)
                        .values(used_in_summary=False)
                    )
                    result = session.execute(stmt)
                    session.commit()
                    logger.info(
                        f"å·²æ¸…é™¤ä»»åŠ¡ {task_id} çš„æ‘˜è¦å†å²è®°å½•ï¼ˆé‡ç½®äº† {result.rowcount} æ¡è®°å½•ï¼‰"
                    )
        except Exception as e:
            logger.error(f"æ¸…é™¤æ‘˜è¦å†å²è®°å½•å¤±è´¥: {e}")
            logger.exception(e)


def get_summary_instance() -> TaskSummaryService:
    """è·å–å…¨å±€ä»»åŠ¡æ‘˜è¦æœåŠ¡å®ä¾‹

    Returns:
        TaskSummaryService å®ä¾‹
    """
    global _global_summary_instance
    if _global_summary_instance is None:
        summary_config = config.get("jobs.task_summary", {})
        min_new_contexts = summary_config.get("min_new_contexts", 5)
        check_interval = summary_config.get("interval", 3600)
        enabled = summary_config.get("enabled", False)

        _global_summary_instance = TaskSummaryService(
            min_new_contexts=min_new_contexts,
            check_interval=check_interval,
            enabled=enabled,
        )
    return _global_summary_instance


def execute_summary_task():
    """æ‰§è¡Œä»»åŠ¡æ‘˜è¦ä»»åŠ¡ï¼ˆä¾›è°ƒåº¦å™¨è°ƒç”¨çš„å¯åºåˆ—åŒ–å‡½æ•°ï¼‰

    è¿™æ˜¯ä¸€ä¸ªæ¨¡å—çº§åˆ«çš„å‡½æ•°ï¼Œå¯ä»¥è¢« APScheduler åºåˆ—åŒ–åˆ°æ•°æ®åº“ä¸­
    """
    try:
        logger.info("ğŸ”„ å¼€å§‹æ‰§è¡Œä»»åŠ¡æ‘˜è¦ä»»åŠ¡")
        summary_service = get_summary_instance()

        if not summary_service.enabled:
            logger.info("ä»»åŠ¡æ‘˜è¦æœåŠ¡æœªå¯ç”¨ï¼Œè·³è¿‡æ‰§è¡Œ")
            return 0

        # æ‰§è¡Œæ‘˜è¦å¤„ç†
        summary_service._process_all_tasks()

        # è¿”å›å¤„ç†ç»Ÿè®¡
        generated = summary_service.stats.get("total_summaries_generated", 0)
        logger.info(f"âœ… ä»»åŠ¡æ‘˜è¦ä»»åŠ¡å®Œæˆï¼Œç”Ÿæˆæ‘˜è¦æ•°: {generated}")
        return generated
    except Exception as e:
        logger.error(f"æ‰§è¡Œä»»åŠ¡æ‘˜è¦ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        return 0
