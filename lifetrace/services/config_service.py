"""é…ç½®æœåŠ¡å±‚ - å¤„ç†é…ç½®çš„ä¿å­˜ã€æ¯”å¯¹å’Œé‡è½½é€»è¾‘"""

import os
import shutil
from collections.abc import Callable
from typing import Any

import yaml

from lifetrace.jobs.scheduler import get_scheduler_manager
from lifetrace.llm.llm_client import LLMClient
from lifetrace.services.asr_client import ASRClient
from lifetrace.util.base_paths import get_config_dir, get_user_config_dir
from lifetrace.util.logging_config import get_logger
from lifetrace.util.settings import reload_settings, settings

logger = get_logger()


# LLM ç›¸å…³é…ç½®é”®ï¼ˆæ”¯æŒä¸¤ç§æ ¼å¼ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦é‡æ–°åˆå§‹åŒ– LLMï¼‰
LLM_RELATED_BACKEND_KEYS = [
    # ç‚¹åˆ†éš”æ ¼å¼ï¼ˆåç«¯æ ‡å‡†ï¼‰
    "llm.api_key",
    "llm.base_url",
    "llm.model",
    # snake_case æ ¼å¼ï¼ˆå‰ç«¯ fetcher è½¬æ¢åå‘é€çš„æ ¼å¼ï¼‰
    "llm_api_key",
    "llm_base_url",
    "llm_model",
]

# ASR ç›¸å…³é…ç½®é”®ï¼ˆæ”¯æŒä¸¤ç§æ ¼å¼ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦é‡æ–°åˆå§‹åŒ– ASRï¼‰
ASR_RELATED_BACKEND_KEYS = [
    # ç‚¹åˆ†éš”æ ¼å¼ï¼ˆåç«¯æ ‡å‡†ï¼‰
    "audio.asr.api_key",
    "audio.asr.base_url",
    "audio.asr.model",
    # snake_case æ ¼å¼ï¼ˆå‰ç«¯ fetcher è½¬æ¢åå‘é€çš„æ ¼å¼ï¼‰
    "audio_asr_api_key",
    "audio_asr_base_url",
    "audio_asr_model",
]

# ä»»åŠ¡å¯ç”¨çŠ¶æ€é…ç½®é”®åˆ°è°ƒåº¦å™¨ä»»åŠ¡IDçš„æ˜ å°„ï¼ˆæ”¯æŒä¸¤ç§æ ¼å¼ï¼‰
JOB_ENABLED_CONFIG_TO_JOB_ID = {
    # ç‚¹åˆ†éš”æ ¼å¼ï¼ˆåç«¯æ ‡å‡†ï¼‰
    "jobs.recorder.enabled": "recorder_job",
    "jobs.ocr.enabled": "ocr_job",
    "jobs.clean_data.enabled": "clean_data_job",
    "jobs.activity_aggregator.enabled": "activity_aggregator_job",
    "jobs.todo_recorder.enabled": "todo_recorder_job",
    "jobs.audio_recording.enabled": "audio_recording_job",
    # snake_case æ ¼å¼ï¼ˆå‰ç«¯ fetcher è½¬æ¢åå‘é€çš„æ ¼å¼ï¼‰
    "jobs_recorder_enabled": "recorder_job",
    "jobs_ocr_enabled": "ocr_job",
    "jobs_clean_data_enabled": "clean_data_job",
    "jobs_activity_aggregator_enabled": "activity_aggregator_job",
    "jobs_todo_recorder_enabled": "todo_recorder_job",
    "jobs_audio_recording_enabled": "audio_recording_job",
}

# è”åŠ¨é…ç½®æ˜ å°„ï¼šé…ç½®é”® -> éœ€è¦è”åŠ¨çš„é…ç½®é”®åˆ—è¡¨
# å½“ä¸€ä¸ªé…ç½®å˜åŒ–æ—¶ï¼Œéœ€è¦åŒæ­¥æ›´æ–°å…³è”çš„é…ç½®
JOB_LINKED_CONFIG = {
    # auto_todo_detection ä¸ todo_recorder è”åŠ¨
    "jobs.auto_todo_detection.enabled": ["jobs.todo_recorder.enabled"],
    "jobs_auto_todo_detection_enabled": ["jobs_todo_recorder_enabled"],
    "jobs.todo_recorder.enabled": ["jobs.auto_todo_detection.enabled"],
    "jobs_todo_recorder_enabled": ["jobs_auto_todo_detection_enabled"],
}


# ç®€å•å‰ç¼€æ˜ å°„ï¼šprefix -> (prefix_length, dot_prefix)
_SIMPLE_PREFIX_MAP: dict[str, tuple[int, str]] = {
    "llm_": (4, "llm"),
    "server_": (7, "server"),
    "chat_": (5, "chat"),
    "dify_": (5, "dify"),
    "tavily_": (7, "tavily"),
}

# ASR é…ç½®é”®åæ˜ å°„ï¼ˆä¿ç•™ä¸‹åˆ’çº¿çš„é”®åï¼‰
_ASR_KEY_MAPPING: dict[str, str] = {
    "audio_asr_api_key": "audio.asr.api_key",
    "audio_asr_base_url": "audio.asr.base_url",
    "audio_asr_model": "audio.asr.model",
    "audio_asr_sample_rate": "audio.asr.sample_rate",
    "audio_asr_format": "audio.asr.format",
    "audio_asr_semantic_punctuation_enabled": "audio.asr.semantic_punctuation_enabled",
    "audio_asr_max_sentence_silence": "audio.asr.max_sentence_silence",
    "audio_asr_heartbeat": "audio.asr.heartbeat",
    "audio_is_24x7": "audio.is_24x7",
}

# å¤åˆä»»åŠ¡åæ˜ å°„ï¼šé¦–éƒ¨åˆ† -> å®Œæ•´ä»»åŠ¡å
_COMPOUND_JOB_NAMES: dict[str, str] = {
    "clean": "clean_data",
    "activity": "activity_aggregator",
    "auto": "auto_todo_detection",
    "todo": "todo_recorder",
}

# æœ€å° jobs é…ç½®éƒ¨åˆ†æ•°é‡
_MIN_JOBS_PARTS = 3


def _convert_jobs_key(parts: list[str]) -> str:
    """è½¬æ¢ jobs ç›¸å…³çš„é…ç½®é”®"""
    job_name = parts[1]  # recorder, ocr, clean_data, activity_aggregator, etc.

    # å¤„ç†å¤åˆä»»åŠ¡å
    if job_name in _COMPOUND_JOB_NAMES:
        full_job_name = _COMPOUND_JOB_NAMES[job_name]
        name_parts = full_job_name.split("_")
        name_length = len(name_parts)

        if len(parts) > name_length and parts[1 : name_length + 1] == name_parts:
            remaining = parts[name_length + 1 :]
            if remaining:
                return f"jobs.{full_job_name}.{'.'.join(remaining)}"
            return f"jobs.{full_job_name}"

    # ç®€å•ä»»åŠ¡å
    remaining = parts[2:]
    if not remaining:
        return f"jobs.{job_name}"

    # å¤„ç† params å­é…ç½®
    if remaining[0] == "params" and len(remaining) > 1:
        return f"jobs.{job_name}.params.{'.'.join(remaining[1:])}"
    return f"jobs.{job_name}.{'.'.join(remaining)}"


def snake_to_dot_notation(key: str) -> str:
    """å°† snake_case æ ¼å¼çš„é”®è½¬æ¢ä¸ºç‚¹åˆ†éš”æ ¼å¼

    å‰ç«¯ fetcher ä¼šå°† camelCase è½¬æ¢ä¸º snake_case å‘é€ç»™åç«¯ï¼Œ
    ä¾‹å¦‚: jobsRecorderEnabled -> jobs_recorder_enabled
    åç«¯é…ç½®æ–‡ä»¶ä½¿ç”¨ç‚¹åˆ†éš”æ ¼å¼ï¼Œä¾‹å¦‚: jobs.recorder.enabled

    Args:
        key: snake_case æ ¼å¼çš„é”®ï¼Œå¦‚ "jobs_recorder_enabled" æˆ– "llm_api_key"

    Returns:
        ç‚¹åˆ†éš”æ ¼å¼çš„é”®ï¼Œå¦‚ "jobs.recorder.enabled" æˆ– "llm.api_key"
    """
    # å¦‚æœå·²ç»æ˜¯ç‚¹åˆ†éš”æ ¼å¼æˆ–ä¸åŒ…å«ä¸‹åˆ’çº¿ï¼Œç›´æ¥è¿”å›
    if "." in key or "_" not in key:
        return key

    # ä¼˜å…ˆæ£€æŸ¥ ASR é…ç½®é”®åæ˜ å°„ï¼ˆéœ€è¦ä¿ç•™ä¸‹åˆ’çº¿çš„é”®ï¼‰
    if key in _ASR_KEY_MAPPING:
        return _ASR_KEY_MAPPING[key]

    # å¤„ç† jobs ç›¸å…³é…ç½®
    if key.startswith("jobs_"):
        parts = key.split("_")
        if parts[0] == "jobs" and len(parts) >= _MIN_JOBS_PARTS:
            return _convert_jobs_key(parts)

    # å¤„ç†ç®€å•å‰ç¼€ï¼ˆllm, server, chatï¼‰
    for prefix, (prefix_len, dot_prefix) in _SIMPLE_PREFIX_MAP.items():
        if key.startswith(prefix):
            return f"{dot_prefix}.{key[prefix_len:]}"

    # é»˜è®¤ï¼šç®€å•åœ°å°†ä¸‹åˆ’çº¿æ›¿æ¢ä¸ºç‚¹
    return key.replace("_", ".")


def dot_to_snake_notation(key: str) -> str:
    """å°†ç‚¹åˆ†éš”æ ¼å¼çš„é”®è½¬æ¢ä¸º snake_case æ ¼å¼

    åç«¯é…ç½®æ–‡ä»¶ä½¿ç”¨ç‚¹åˆ†éš”æ ¼å¼ï¼Œä¾‹å¦‚: jobs.recorder.enabled
    å‰ç«¯ fetcher éœ€è¦ snake_case æ ¼å¼æ‰èƒ½è½¬æ¢ä¸º camelCaseï¼Œä¾‹å¦‚: jobs_recorder_enabled

    Args:
        key: ç‚¹åˆ†éš”æ ¼å¼çš„é”®ï¼Œå¦‚ "jobs.recorder.enabled" æˆ– "llm.api_key"

    Returns:
        snake_case æ ¼å¼çš„é”®ï¼Œå¦‚ "jobs_recorder_enabled" æˆ– "llm_api_key"
    """
    # å¦‚æœå·²ç»æ˜¯ snake_case æ ¼å¼æˆ–ä¸åŒ…å«ç‚¹ï¼Œç›´æ¥è¿”å›
    if "." not in key:
        return key

    # ç®€å•åœ°å°†ç‚¹æ›¿æ¢ä¸ºä¸‹åˆ’çº¿
    return key.replace(".", "_")


def is_llm_configured() -> bool:
    """æ£€æŸ¥ LLM æ˜¯å¦å·²é…ç½®

    Returns:
        bool: å¦‚æœ llm_key å’Œ base_url éƒ½å·²é…ç½®ï¼ˆä¸æ˜¯å ä½ç¬¦æˆ–ç©ºï¼‰ï¼Œè¿”å› True
    """
    invalid_values = ["", "xxx", "YOUR_API_KEY_HERE", "YOUR_BASE_URL_HERE", "YOUR_LLM_KEY_HERE"]
    return (
        settings.llm.api_key not in invalid_values and settings.llm.base_url not in invalid_values
    )


class ConfigService:
    """é…ç½®æœåŠ¡ç±» - è´Ÿè´£é…ç½®çš„ä¿å­˜ã€æ¯”å¯¹å’Œçƒ­åŠ è½½"""

    def __init__(self):
        """åˆå§‹åŒ–é…ç½®æœåŠ¡"""
        self._config_path = str(get_user_config_dir() / "config.yaml")

    def compare_config_changes(self, new_settings: dict[str, Any]) -> tuple[bool, list[str]]:
        """æ¯”å¯¹é…ç½®å˜æ›´

        Args:
            new_settings: å‰ç«¯æäº¤çš„é…ç½®å­—å…¸ï¼ˆé”®å¯ä»¥æ˜¯ snake_case æˆ–ç‚¹åˆ†éš”æ ¼å¼ï¼‰

        Returns:
            (æ˜¯å¦æœ‰å˜æ›´, å˜æ›´é¡¹åˆ—è¡¨)
        """
        config_changed = False
        changed_items = []

        for raw_key, new_value in new_settings.items():
            # å°† snake_case æ ¼å¼è½¬æ¢ä¸ºç‚¹åˆ†éš”æ ¼å¼
            backend_key = snake_to_dot_notation(raw_key)
            try:
                # è·å–å½“å‰é…ç½®å€¼
                old_value = settings.get(backend_key)

                # æ¯”å¯¹æ–°æ—§å€¼
                if old_value != new_value:
                    config_changed = True
                    # è®°å½•å˜æ›´é¡¹ï¼ˆæ•æ„Ÿä¿¡æ¯è„±æ•ï¼‰
                    if "api_key" in backend_key.lower():
                        changed_items.append(
                            f"{backend_key}: {str(old_value)[:10] if old_value else 'None'}... -> {str(new_value)[:10]}..."
                        )
                    else:
                        changed_items.append(f"{backend_key}: {old_value} -> {new_value}")
            except KeyError:
                # é…ç½®é¡¹ä¸å­˜åœ¨ï¼Œè§†ä¸ºæ–°å¢é…ç½®
                config_changed = True
                if "api_key" in backend_key.lower():
                    changed_items.append(f"{backend_key}: (æ–°å¢) {str(new_value)[:10]}...")
                else:
                    changed_items.append(f"{backend_key}: (æ–°å¢) {new_value}")

        return config_changed, changed_items

    def get_llm_config(self) -> dict[str, Any]:
        """è·å–å½“å‰ LLM é…ç½®

        Returns:
            LLM é…ç½®å­—å…¸
        """
        return {
            "api_key": settings.llm.api_key,
            "base_url": settings.llm.base_url,
            "model": settings.llm.model,
        }

    def get_asr_config(self) -> dict[str, Any]:
        """è·å–å½“å‰ ASR é…ç½®

        Returns:
            ASR é…ç½®å­—å…¸
        """
        try:
            return {
                "api_key": settings.audio.asr.api_key,
                "base_url": settings.audio.asr.base_url,
                "model": settings.audio.asr.model,
            }
        except Exception:
            return {
                "api_key": None,
                "base_url": None,
                "model": None,
            }

    def get_config_for_frontend(self) -> dict[str, Any]:
        """è·å–é…ç½®ï¼ˆè½¬æ¢ä¸º snake_case æ ¼å¼ä¾›å‰ç«¯ä½¿ç”¨ï¼‰

        å‰ç«¯ fetcher ä¼šå°† snake_case è½¬æ¢ä¸º camelCaseã€‚
        åç«¯é…ç½®æ–‡ä»¶ä½¿ç”¨ç‚¹åˆ†éš”æ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸º snake_case æ ¼å¼ã€‚

        Returns:
            snake_case æ ¼å¼çš„é…ç½®å­—å…¸ï¼Œå‰ç«¯ fetcher ä¼šè‡ªåŠ¨è½¬æ¢ä¸º camelCase
        """
        # å®šä¹‰éœ€è¦è·å–çš„é…ç½®é¡¹ï¼ˆåç«¯æ ¼å¼ï¼‰
        backend_config_keys = [
            # å½•åˆ¶é…ç½®
            "jobs.recorder.params.auto_exclude_self",
            "jobs.recorder.params.blacklist.enabled",
            "jobs.recorder.params.blacklist.apps",
            "jobs.recorder.enabled",
            "jobs.recorder.interval",
            "jobs.recorder.params.screens",
            "jobs.recorder.params.deduplicate",
            # LLMé…ç½®
            "llm.api_key",
            "llm.base_url",
            "llm.model",
            "llm.temperature",
            "llm.max_tokens",
            # æœåŠ¡å™¨é…ç½®
            "server.host",
            "server.port",
            # Clean data é…ç½®
            "jobs.clean_data.params.max_days",
            "jobs.clean_data.params.max_screenshots",
            # èŠå¤©é…ç½®
            "chat.enable_history",
            "chat.history_limit",
            # è‡ªåŠ¨å¾…åŠæ£€æµ‹é…ç½®
            "jobs.auto_todo_detection.enabled",
            "jobs.auto_todo_detection.params.whitelist.apps",
            # Todo ä¸“ç”¨å½•åˆ¶é…ç½®
            "jobs.todo_recorder.enabled",
            "jobs.todo_recorder.interval",
            # Dify é…ç½®
            "dify.enabled",
            "dify.api_key",
            "dify.base_url",
            # Tavily é…ç½®ï¼ˆè”ç½‘æœç´¢ï¼‰
            "tavily.api_key",
            # éŸ³é¢‘å½•åˆ¶é…ç½®
            "audio.is_24x7",
            # éŸ³é¢‘å½•åˆ¶ä»»åŠ¡é…ç½®
            "jobs.audio_recording.enabled",
            "jobs.audio_recording.interval",
            # éŸ³é¢‘è¯†åˆ«ï¼ˆASRï¼‰é…ç½®
            "audio.asr.api_key",
            "audio.asr.base_url",
            "audio.asr.model",
            "audio.asr.sample_rate",
            "audio.asr.format",
            "audio.asr.semantic_punctuation_enabled",
            "audio.asr.max_sentence_silence",
            "audio.asr.heartbeat",
        ]

        config_dict = {}
        for backend_key in backend_config_keys:
            try:
                value = settings.get(backend_key)
                # å°†ç‚¹åˆ†éš”æ ¼å¼è½¬æ¢ä¸º snake_case æ ¼å¼ï¼Œä»¥ä¾¿å‰ç«¯ fetcher èƒ½æ­£ç¡®è½¬æ¢ä¸º camelCase
                frontend_key = dot_to_snake_notation(backend_key)
                config_dict[frontend_key] = value
            except KeyError:
                # é…ç½®é¡¹ä¸å­˜åœ¨ï¼Œè·³è¿‡æˆ–ä½¿ç”¨é»˜è®¤å€¼
                logger.debug(f"é…ç½®é¡¹ {backend_key} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                continue

        return config_dict

    def update_config_file(self, new_settings: dict[str, Any], config_path: str) -> None:
        """æ›´æ–°é…ç½®æ–‡ä»¶

        Args:
            new_settings: é…ç½®å­—å…¸ï¼ˆé”®å¯ä»¥æ˜¯ snake_case æˆ–ç‚¹åˆ†éš”æ ¼å¼ï¼‰
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        # è¯»å–ç°æœ‰é…ç½®
        with open(config_path, encoding="utf-8") as f:
            current_config = yaml.safe_load(f) or {}

        # æ›´æ–°é…ç½®
        for raw_key, value in new_settings.items():
            # å°† snake_case æ ¼å¼è½¬æ¢ä¸ºç‚¹åˆ†éš”æ ¼å¼
            backend_key = snake_to_dot_notation(raw_key)
            logger.info(f"æ›´æ–°é…ç½®: {raw_key} -> {backend_key} = {value}")

            # å¤„ç†åµŒå¥—é…ç½®é”®
            keys = backend_key.split(".")
            current = current_config
            for key in keys[:-1]:
                if key not in current:
                    current[key] = {}
                current = current[key]
            current[keys[-1]] = value

        # ä¿å­˜é…ç½®æ–‡ä»¶
        with open(config_path, "w", encoding="utf-8") as f:
            yaml.dump(current_config, f, allow_unicode=True, sort_keys=False)

        logger.info(f"é…ç½®å·²ä¿å­˜åˆ°: {config_path}")

    def _collect_jobs_to_sync(
        self, job_config_keys: list[str], new_settings: dict[str, Any]
    ) -> dict[str, bool]:
        """æ”¶é›†éœ€è¦åŒæ­¥çš„ä»»åŠ¡ï¼ˆåŒ…æ‹¬è”åŠ¨ä»»åŠ¡ï¼‰"""
        jobs_to_sync: dict[str, bool] = {}

        for config_key in job_config_keys:
            job_id = JOB_ENABLED_CONFIG_TO_JOB_ID[config_key]
            enabled = new_settings[config_key]
            jobs_to_sync[job_id] = enabled

            # æ£€æŸ¥æ˜¯å¦æœ‰è”åŠ¨é…ç½®
            if config_key in JOB_LINKED_CONFIG:
                self._add_linked_jobs(config_key, job_id, enabled, jobs_to_sync)

        return jobs_to_sync

    def _add_linked_jobs(
        self, config_key: str, job_id: str, enabled: bool, jobs_to_sync: dict[str, bool]
    ) -> None:
        """æ·»åŠ è”åŠ¨ä»»åŠ¡åˆ°åŒæ­¥åˆ—è¡¨"""
        linked_keys = JOB_LINKED_CONFIG[config_key]
        for linked_key in linked_keys:
            if linked_key in JOB_ENABLED_CONFIG_TO_JOB_ID:
                linked_job_id = JOB_ENABLED_CONFIG_TO_JOB_ID[linked_key]
                if linked_job_id not in jobs_to_sync:
                    jobs_to_sync[linked_job_id] = enabled
                    logger.info(f"ğŸ“¢ è”åŠ¨åŒæ­¥ï¼š{job_id} -> {linked_job_id} = {enabled}")

    def sync_job_states_if_needed(self, new_settings: dict[str, Any]) -> None:
        """å¦‚æœä»»åŠ¡å¯ç”¨çŠ¶æ€å‘ç”Ÿå˜åŒ–ï¼ŒåŒæ­¥åˆ°è°ƒåº¦å™¨

        Args:
            new_settings: é…ç½®å­—å…¸ï¼ˆé”®å¯ä»¥æ˜¯ snake_case æˆ–ç‚¹åˆ†éš”æ ¼å¼ï¼‰
        """
        job_config_keys = [key for key in new_settings if key in JOB_ENABLED_CONFIG_TO_JOB_ID]

        if not job_config_keys:
            return

        try:
            scheduler_manager = get_scheduler_manager()
            jobs_to_sync = self._collect_jobs_to_sync(job_config_keys, new_settings)

            for job_id, enabled in jobs_to_sync.items():
                job = scheduler_manager.get_job(job_id)
                if not job:
                    logger.warning(f"ä»»åŠ¡ {job_id} ä¸å­˜åœ¨ï¼Œè·³è¿‡çŠ¶æ€åŒæ­¥")
                    continue

                is_running = job.next_run_time is not None
                if enabled and not is_running:
                    scheduler_manager.resume_job(job_id)
                    logger.info(f"ğŸ“¢ é…ç½®å˜æ›´ï¼šä»»åŠ¡ {job_id} å·²æ¢å¤è¿è¡Œ")
                elif not enabled and is_running:
                    scheduler_manager.pause_job(job_id)
                    logger.info(f"ğŸ“¢ é…ç½®å˜æ›´ï¼šä»»åŠ¡ {job_id} å·²æš‚åœ")

        except Exception as e:
            logger.error(f"åŒæ­¥ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}", exc_info=True)

    def reinitialize_llm_if_needed(
        self,
        new_settings: dict[str, Any],
        old_llm_config: dict[str, Any],
        is_llm_configured_callback: Callable[[], None] | None = None,
    ) -> None:
        """å¦‚æœ LLM é…ç½®å‘ç”Ÿå˜åŒ–ï¼Œé‡æ–°åˆå§‹åŒ– LLM å®¢æˆ·ç«¯

        Args:
            new_settings: é…ç½®å­—å…¸ï¼ˆé”®ä¸ºåç«¯æ ¼å¼ï¼‰
            old_llm_config: æ—§çš„ LLM é…ç½®
            is_llm_configured_callback: æ›´æ–° LLM é…ç½®çŠ¶æ€çš„å›è°ƒå‡½æ•°
        """
        # æ£€æµ‹æ˜¯å¦æœ‰ LLM ç›¸å…³é…ç½®é¡¹åœ¨è¯·æ±‚ä¸­
        has_llm_keys = any(key in LLM_RELATED_BACKEND_KEYS for key in new_settings)

        if not has_llm_keys:
            return

        # è·å–æ–°çš„ LLM é…ç½®å€¼
        new_llm_config = self.get_llm_config()

        # æ¯”å¯¹æ–°æ—§é…ç½®å€¼
        llm_config_changed = old_llm_config != new_llm_config

        if llm_config_changed:
            logger.info("æ£€æµ‹åˆ° LLM é…ç½®å®é™…å‘ç”Ÿå˜æ›´ï¼Œæ­£åœ¨çƒ­åŠ è½½ LLM å®¢æˆ·ç«¯...")
            logger.info(
                f"æ—§é…ç½®: API Key={old_llm_config['api_key'][:10] if old_llm_config['api_key'] else 'None'}..., "
                f"Base URL={old_llm_config['base_url']}, Model={old_llm_config['model']}"
            )
            logger.info(
                f"æ–°é…ç½®: API Key={new_llm_config['api_key'][:10] if new_llm_config['api_key'] else 'None'}..., "
                f"Base URL={new_llm_config['base_url']}, Model={new_llm_config['model']}"
            )

            try:
                # æ›´æ–°é…ç½®çŠ¶æ€
                if is_llm_configured_callback:
                    is_llm_configured_callback()

                configured = is_llm_configured()
                status = "å·²é…ç½®" if configured else "æœªé…ç½®"
                logger.info(f"LLM é…ç½®çŠ¶æ€å·²æ›´æ–°: {status}")

                # é‡æ–°åˆå§‹åŒ– LLM å®¢æˆ·ç«¯å•ä¾‹ï¼ˆæ‰€æœ‰æœåŠ¡å…±äº«æ­¤å®ä¾‹ï¼‰
                llm_client = LLMClient()
                client_available = llm_client.reinitialize()
                logger.info(f"LLM å®¢æˆ·ç«¯å·²é‡æ–°åˆå§‹åŒ– - å¯ç”¨: {client_available}")

                if client_available:
                    logger.info(
                        f"LLM å®¢æˆ·ç«¯çƒ­åŠ è½½æˆåŠŸ - "
                        f"API Key: {llm_client.api_key[:10]}..., "
                        f"Model: {llm_client.model}"
                    )
                    logger.info("æ‰€æœ‰æœåŠ¡å°†è‡ªåŠ¨ä½¿ç”¨æ›´æ–°åçš„ LLM å®¢æˆ·ç«¯")
                else:
                    logger.warning("LLM å®¢æˆ·ç«¯é‡æ–°åˆå§‹åŒ–åä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥é…ç½®")

                logger.info("LLM é…ç½®çƒ­åŠ è½½å®Œæˆ")
            except Exception as e:
                logger.error(f"çƒ­åŠ è½½ LLM å®¢æˆ·ç«¯å¤±è´¥: {e}", exc_info=True)
        else:
            logger.info("LLM é…ç½®æœªå‘ç”Ÿå®é™…å˜æ›´ï¼Œè·³è¿‡é‡æ–°åŠ è½½")

    def reinitialize_asr_if_needed(
        self,
        new_settings: dict[str, Any],
        old_asr_config: dict[str, Any],
    ) -> None:
        """å¦‚æœ ASR é…ç½®å‘ç”Ÿå˜åŒ–ï¼Œé‡æ–°åˆå§‹åŒ– ASR å®¢æˆ·ç«¯

        Args:
            new_settings: é…ç½®å­—å…¸ï¼ˆé”®ä¸ºåç«¯æ ¼å¼ï¼‰
            old_asr_config: æ—§çš„ ASR é…ç½®
        """
        # æ£€æµ‹æ˜¯å¦æœ‰ ASR ç›¸å…³é…ç½®é¡¹åœ¨è¯·æ±‚ä¸­
        has_asr_keys = any(key in ASR_RELATED_BACKEND_KEYS for key in new_settings)

        if not has_asr_keys:
            return

        # è·å–æ–°çš„ ASR é…ç½®å€¼
        new_asr_config = self.get_asr_config()

        # æ¯”å¯¹æ–°æ—§é…ç½®å€¼
        asr_config_changed = old_asr_config != new_asr_config

        if asr_config_changed:
            logger.info("æ£€æµ‹åˆ° ASR é…ç½®å®é™…å‘ç”Ÿå˜æ›´ï¼Œæ­£åœ¨çƒ­åŠ è½½ ASR å®¢æˆ·ç«¯...")
            logger.info(
                f"æ—§é…ç½®: API Key={old_asr_config['api_key'][:10] if old_asr_config['api_key'] else 'None'}..., "
                f"Base URL={old_asr_config['base_url']}, Model={old_asr_config['model']}"
            )
            logger.info(
                f"æ–°é…ç½®: API Key={new_asr_config['api_key'][:10] if new_asr_config['api_key'] else 'None'}..., "
                f"Base URL={new_asr_config['base_url']}, Model={new_asr_config['model']}"
            )

            try:
                # é‡æ–°åˆå§‹åŒ– ASR å®¢æˆ·ç«¯å•ä¾‹
                asr_client = ASRClient()
                asr_client.reinitialize()
                logger.info(
                    f"ASR å®¢æˆ·ç«¯çƒ­åŠ è½½æˆåŠŸ - "
                    f"API Key: {asr_client.api_key[:10] if asr_client.api_key else 'None'}..., "
                    f"Model: {asr_client.model}"
                )
                logger.info("ASR é…ç½®çƒ­åŠ è½½å®Œæˆ")
            except Exception as e:
                logger.error(f"çƒ­åŠ è½½ ASR å®¢æˆ·ç«¯å¤±è´¥: {e}", exc_info=True)
        else:
            logger.info("ASR é…ç½®æœªå‘ç”Ÿå®é™…å˜æ›´ï¼Œè·³è¿‡é‡æ–°åŠ è½½")

    def save_config(
        self,
        new_settings: dict[str, Any],
        is_llm_configured_callback: Callable[[], None] | None = None,
    ) -> dict[str, Any]:
        """ä¿å­˜é…ç½®ï¼ˆä¸»å…¥å£æ–¹æ³•ï¼‰

        Args:
            new_settings: é…ç½®å­—å…¸ï¼ˆé”®ä¸ºåç«¯æ ¼å¼ï¼‰
            is_llm_configured_callback: æ›´æ–° LLM é…ç½®çŠ¶æ€çš„å›è°ƒå‡½æ•°

        Returns:
            æ“ä½œç»“æœå­—å…¸
        """
        config_path = self._config_path

        # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä»é»˜è®¤é…ç½®å¤åˆ¶
        if not os.path.exists(config_path):
            self._init_config_file()

        # 1. å…ˆæ¯”å¯¹é…ç½®æ˜¯å¦çœŸçš„å‘ç”Ÿäº†å˜åŒ–
        config_changed, changed_items = self.compare_config_changes(new_settings)

        # å¦‚æœé…ç½®æ²¡æœ‰å‘ç”Ÿå˜åŒ–ï¼Œç›´æ¥è¿”å›
        if not config_changed:
            logger.info("é…ç½®æœªå‘ç”Ÿå˜åŒ–ï¼Œè·³è¿‡ä¿å­˜å’Œé‡è½½")
            return {"success": True, "message": "é…ç½®æœªå‘ç”Ÿå˜åŒ–"}

        # è®°å½•å˜æ›´ä¿¡æ¯
        logger.info(f"æ£€æµ‹åˆ°é…ç½®å˜æ›´ï¼Œå…± {len(changed_items)} é¡¹:")
        for item in changed_items:
            logger.info(f"  - {item}")

        # 2. ä¿å­˜æ—§çš„ LLM å’Œ ASR é…ç½®å€¼ï¼ˆç”¨äºåç»­æ¯”å¯¹æ˜¯å¦éœ€è¦é‡æ–°åˆå§‹åŒ–ï¼‰
        old_llm_config = self.get_llm_config()
        old_asr_config = self.get_asr_config()

        # 3. æ›´æ–°é…ç½®æ–‡ä»¶
        self.update_config_file(new_settings, config_path)

        # 4. é‡æ–°åŠ è½½é…ç½®ï¼ˆä½¿ç”¨å°è£…å‡½æ•°ï¼Œæ­£ç¡®å¤„ç†è¿”å›å€¼ï¼‰
        reload_success = reload_settings()
        if reload_success:
            logger.info("é…ç½®å·²é‡æ–°åŠ è½½åˆ°å†…å­˜")
        else:
            logger.warning("é…ç½®é‡æ–°åŠ è½½å¤±è´¥ï¼Œä½†æ–‡ä»¶å·²ä¿å­˜")

        # 5. åŒæ­¥ä»»åŠ¡çŠ¶æ€åˆ°è°ƒåº¦å™¨ï¼ˆåœ¨é…ç½®é‡è½½åæ‰§è¡Œï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°çš„é…ç½®å€¼ï¼‰
        self.sync_job_states_if_needed(new_settings)

        # 6. å¦‚æœéœ€è¦ï¼Œé‡æ–°åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        self.reinitialize_llm_if_needed(new_settings, old_llm_config, is_llm_configured_callback)

        # 7. å¦‚æœéœ€è¦ï¼Œé‡æ–°åˆå§‹åŒ– ASR å®¢æˆ·ç«¯
        self.reinitialize_asr_if_needed(new_settings, old_asr_config)

        return {"success": True, "message": "é…ç½®ä¿å­˜æˆåŠŸ"}

    def _init_config_file(self) -> None:
        """ä»é»˜è®¤é…ç½®åˆå§‹åŒ–é…ç½®æ–‡ä»¶"""
        default_config_path = get_config_dir() / "default_config.yaml"

        if not default_config_path.exists():
            raise FileNotFoundError(
                f"é»˜è®¤é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {default_config_path}\n"
                "è¯·ç¡®ä¿ default_config.yaml æ–‡ä»¶å­˜åœ¨äº config ç›®å½•ä¸­"
            )

        os.makedirs(os.path.dirname(self._config_path), exist_ok=True)
        shutil.copy2(default_config_path, self._config_path)
        reload_settings()
